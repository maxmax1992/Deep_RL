{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import keras\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D\n",
    "import cv2\n",
    "\n",
    "random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('Breakout-v0')\n",
    "env.reset()\n",
    "\n",
    "\n",
    "def preprocess(observation):\n",
    "    observation = cv2.cvtColor(cv2.resize(observation, (84, 84)), cv2.COLOR_BGR2GRAY)\n",
    "    ret, observation = cv2.threshold(observation,1,255,cv2.THRESH_BINARY)\n",
    "    return np.reshape(observation,(84,84,1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Architecture\n",
    "Images based on deepminds DRL research and Stanfords Deep Learning course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep ConvNet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQN():\n",
    "    def __init__(self, inputWidth=84, inputHeight=84, zSize=4):\n",
    "        self.model = Sequential()\n",
    "        model = self.model\n",
    "        data_format=None\n",
    "        model.add(Conv2D(32, (8, 8), strides=(4, 4), activation='relu', \n",
    "                        input_shape=(inputWidth, inputHeight, 4)))\n",
    "        model.add(Conv2D(64, (4, 4), strides=(2, 2), activation='relu'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dense(4, activation='softmax'))\n",
    "        \n",
    "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "    #passed X and Y buffer to training\n",
    "    def train(self, x_train, y_train):\n",
    "        model.fit(x_train, y_train,\n",
    "          epochs=1,\n",
    "          batch_size=32, shuffle=True)\n",
    "        \n",
    "    def getModel(self):\n",
    "        return self.model\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Replay memory buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class replay_Memory():\n",
    "    def __init__(self, maxSize=2000):\n",
    "        self.maxSize = maxSize\n",
    "        self.memory = np.array([])\n",
    "        \n",
    "    def addUnit(self, unit):\n",
    "        if len(self.memory) + 1 > self.maxSize: \n",
    "            newList = np.random.choice(self.memory, len(self.memory)-1)\n",
    "            self.memory = np.append(newList, unit)\n",
    "        else:\n",
    "            self.memory = np.append(self.memory, unit)\n",
    "            \n",
    "    def getMemory(self):\n",
    "        return self.memory\n",
    "    \n",
    "    \n",
    "    def getBatch(self, batch_length):\n",
    "        memlen = len(self.memory)\n",
    "        if batch_length > memlen:\n",
    "            return np.random.choice(self.memory, memlen)\n",
    "        else:\n",
    "            return np.random.choice(self.memory, length)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/pseudocode.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.models.Sequential object at 0x1380340b8>\n",
      "<keras.models.Sequential object at 0x1380340b8>\n",
      "[[  4.47580295e-19   1.00000000e+00   6.11539651e-31   4.70457007e-15]]\n",
      "1\n",
      "(1, 4, 84, 84, 1)\n",
      "\n",
      "prediction [[  4.47580295e-19   1.00000000e+00   6.11539651e-31   4.70457007e-15]]\n",
      "q_value\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_82 to have 2 dimensions, but got array with shape (1, 1, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-61ea70409faa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;31m#                 print((np.swapaxes(np.squeeze(X, axis=4),1, 3)).shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0;31m#perform gradient step update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;31m#every TARGET_UDPATE_STEP step copy weights to target network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1591\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1592\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1593\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1594\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1431\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1432\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    108\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_82 to have 2 dimensions, but got array with shape (1, 1, 4)"
     ]
    }
   ],
   "source": [
    "#class that is representing single transition in replay memory\n",
    "class Transition():\n",
    "    \n",
    "    def __init__(self, observation0, action, reward, observation1, isTerminal):\n",
    "        self.isTerminal = isTerminal\n",
    "        self.obs0 = observation0\n",
    "        self.action = action\n",
    "        self.reward = reward\n",
    "        self.obs1 = observation1\n",
    "    \n",
    "    def getObs(self, index):\n",
    "        if index == 0:\n",
    "            return self.obs0\n",
    "        elif index == 1:\n",
    "            return self.obs1\n",
    "        else:\n",
    "            raise Excetion('Error', 'Invalid index of observation given in transition getter')\n",
    "\n",
    "    def isTerminal():\n",
    "        return self.isTerminal\n",
    "    \n",
    "    def getReward(self):\n",
    "        return self.reward\n",
    "    \n",
    "    def getAction(self):\n",
    "        return self.action\n",
    "    \n",
    "        \n",
    "\n",
    "def get_actions(st, model):\n",
    "    if len(st) != 4:\n",
    "        raise Exception('Error', 'stateProcessingError!')\n",
    "    st = np.dstack((st[0], st[1], st[2], st[3]))\n",
    "    return model.predict(np.array([st]))\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "memory = replay_Memory()\n",
    "\n",
    "#initialize dqn\n",
    "q = DQN()\n",
    "\n",
    "#initialize target dqn\n",
    "q_target_model = keras.models.clone_model(q.getModel())\n",
    "q_target_model.set_weights(q.getModel().get_weights())\n",
    "\n",
    "\n",
    "#what percentage of actions are random (improves exploartion rate of the algorithm)\n",
    "\n",
    "\n",
    "#constants\n",
    "EPSILON_EXPLORATION = 0.01\n",
    "TARGET_UPDATE_TICK = 0\n",
    "TARGET_UDPATE_STEP = 4\n",
    "DISCOUNT_CONSTANT = 0.99\n",
    "REPEAT_ACTION_N = 4\n",
    "\n",
    "\n",
    "for episode in range (1, 10):\n",
    "    \n",
    "    state_t = env.reset()\n",
    "    totalReward = 0\n",
    "    tick = 0\n",
    "    \n",
    "    done = False\n",
    "    lastAction = 0\n",
    "    \n",
    "    recentStates = deque([], maxlen=4)\n",
    "    \n",
    "    while not done:\n",
    "        #repeat 3 same actions on same frame\n",
    "        if tick < REPEAT_ACTION_N:\n",
    "            observation, reward, done, info = env.step(lastAction)\n",
    "            recentStates.append(preprocess(observation))\n",
    "            tick += 1\n",
    "        else:\n",
    "            randval = random.uniform(0, 1)\n",
    "\n",
    "            #perform random action\n",
    "            if randval <= EPSILON_EXPLORATION:\n",
    "                lastAction = env.action_space.sample()\n",
    "                observation, reward, done, info = env.step(lastAction)   \n",
    "                recentStates.append(preprocess(observation))\n",
    "            #perform DQN action\n",
    "            else:\n",
    "                \n",
    "                #get optimal action\n",
    "                optimal_action = np.argmax(get_actions(recentStates, q.getModel())[0])\n",
    "                print(get_actions(recentStates, q.getModel()))\n",
    "                #execute optimal action\n",
    "                observation, reward, done, info = env.step(optimal_action)\n",
    "                \n",
    "                obs_t0 = recentStates.copy()\n",
    "                recentStates.append(preprocess(observation))\n",
    "                obs_t1 = recentStates.copy()\n",
    "                \n",
    "                #save transition in replay memory\n",
    "                transition = Transition(obs_t0, optimal_action, reward, obs_t1, isTerminal=done)\n",
    "                \n",
    "                memory.addUnit(transition)\n",
    "                \n",
    "                #batch = [{ob1, an, r, ob2}...]\n",
    "                batch = memory.getBatch(32)\n",
    "                \n",
    "                #get X for training\n",
    "                X = []\n",
    "                for sample in batch:\n",
    "                    X.append(sample.getObs(0))\n",
    "                X = np.array(X)\n",
    "                print(X.shape)\n",
    "                print()\n",
    "\n",
    "                \n",
    "                #get Y for training\n",
    "                Y = []\n",
    "                #get the correct Y values\n",
    "                for sample in batch:\n",
    "                    \n",
    "                    action = sample.getAction()\n",
    "                    prediction = get_actions(sample.getObs(0), q.getModel())\n",
    "                    \n",
    "                    # set target as r\n",
    "                    if sample.isTerminal:\n",
    "                        prediction[action] = sample.getReward()\n",
    "                        \n",
    "                    #set target as rt + discount_factor*max(Q(st + 1, a_))    \n",
    "                    else:\n",
    "                        max_actionVal = np.max( get_actions(sample.getObs(1), q_target_model) )\n",
    "                        q_value = sample.getReward() + DISCOUNT_CONSTANT * max_actionVal\n",
    "                        \n",
    "                        print('prediction', prediction)\n",
    "                        print('q_value')\n",
    "                        prediction[0][action] = q_value\n",
    "                        \n",
    "                    Y.append(prediction)\n",
    "                Y = np.array(Y)\n",
    "                    \n",
    "                #perform gradient step update\n",
    "                q.getModel().fit(x = np.swapaxes(np.squeeze(X, axis=4),1, 3), y = Y, batch_size=len(batch))\n",
    "                \n",
    "                #every TARGET_UDPATE_STEP step copy weights to target network\n",
    "                if TARGET_UPDATE_TICK >= TARGET_UDPATE_STEP:\n",
    "                    TARGET_UPDATE_TICK = 0\n",
    "                    q_target_model.set_weights(q.getModel().get_weights())\n",
    "                    \n",
    "                TARGET_UPDATE_TICK += 1\n",
    "            tick = 1\n",
    "        env.render()\n",
    "                \n",
    "    env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
