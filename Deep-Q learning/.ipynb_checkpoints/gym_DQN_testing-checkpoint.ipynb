{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/Home/anaconda3/envs/gym/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import keras\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D\n",
    "import cv2\n",
    "from collections import deque\n",
    "import os.path\n",
    "\n",
    "\n",
    "random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('Breakout-v0')\n",
    "env.reset()\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(observation):\n",
    "    observation = cv2.cvtColor(cv2.resize(observation, (84, 110)), cv2.COLOR_BGR2GRAY)\n",
    "    observation = observation[26:110,:]\n",
    "    return np.reshape(observation,(84,84,1))\n",
    "\n",
    "# def preprocess(observation):\n",
    "#     observation = cv2.cvtColor(cv2.resize(observation, (84, 84)), cv2.COLOR_BGR2GRAY)\n",
    "# #     ret, observation = cv2.threshold(observation,1,255,cv2.THRESH_BINARY)\n",
    "#     return np.reshape(observation,(84,84,1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Architecture\n",
    "Images based on deepminds DRL research and Stanfords Deep Learning course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep ConvNet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQN():\n",
    "    def __init__(self, inputWidth=84, inputHeight=84, zSize=4):\n",
    "        self.model = Sequential()\n",
    "        model = self.model\n",
    "        data_format=None\n",
    "        model.add(Conv2D(32, (8, 8), strides=(4, 4), activation='relu', \n",
    "                        input_shape=(inputWidth, inputHeight, 4)))\n",
    "        model.add(Conv2D(64, (4, 4), strides=(2, 2), activation='relu'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(4))\n",
    "        \n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        if os.path.exists('breakout-v0-weights-v0.h5'):\n",
    "            self.loadModel()\n",
    "            print('loaded nn weights from file')\n",
    "\n",
    "        print('Initializing random nn')\n",
    "        \n",
    "    #passed X and Y buffer to training\n",
    "        \n",
    "        \n",
    "    def saveModel(self):\n",
    "        self.model.save_weights('breakout-v0-weights-v0.h5')\n",
    "        \n",
    "    def loadModel(self):\n",
    "        self.model.load_weights('breakout-v0-weights-v0.h5')\n",
    "\n",
    "    def getModel(self):\n",
    "        return self.model\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Replay memory buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class replay_Memory():\n",
    "    def __init__(self, maxSize=2000):\n",
    "        self.maxSize = maxSize\n",
    "        self.memory = np.array([])\n",
    "        \n",
    "    def addUnit(self, unit):\n",
    "        if len(self.memory) + 1 > self.maxSize: \n",
    "            self.memory = np.append(self.memory[1:len(self.memory)], unit)\n",
    "        else:\n",
    "            self.memory = np.append(self.memory, unit)\n",
    "            \n",
    "    def getMemory(self):\n",
    "        return self.memory\n",
    "    \n",
    "    \n",
    "    def getBatch(self, batch_length):\n",
    "        memlen = len(self.memory)\n",
    "        if batch_length > memlen:\n",
    "            return np.random.choice(self.memory, memlen)\n",
    "        else:\n",
    "            return np.random.choice(self.memory, batch_length)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/pseudocode.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EPSILON_EXPLORATION = 0.01\n",
    "# TARGET_UPDATE_TICK = 0\n",
    "# TARGET_UDPATE_STEP = 4\n",
    "# DISCOUNT_CONSTANT = 0.99\n",
    "# REPEAT_ACTION_N = 4\n",
    "\n",
    "\n",
    "# for episode in range(1, 1001):\n",
    "#     totalReward, reward = 0,0\n",
    "#     state = env.reset()\n",
    "#     done = False\n",
    "    \n",
    "    \n",
    "#     while not done:\n",
    "#         nextState, reward, done, info = env.step(random.randint(0, env.action_space.n -1))\n",
    "#         totalReward += reward\n",
    "#         env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded nn weights from file\n",
      "Initializing random nn\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13622d940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1345b1630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x136c95ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x136922860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred0 [-0.0034638   0.01416062  0.00484175 -0.00166871]\n",
      "pred1 [-0.01393455  0.00913485  0.00252829 -0.00023831]\n",
      "pred0 [-0.02635694  0.00713459 -0.00021636  0.0014587 ]\n",
      "pred1 [-0.02403104  0.00614701  0.00029752  0.00114097]\n",
      "pred0 [-0.08033782 -0.00301377 -0.01214316  0.00883299]\n",
      "pred1 [-0.08043194 -0.00415494 -0.01216397  0.00650679]\n",
      "pred0 [ 0.01403093  0.01133579  0.00870711 -0.00614182]\n",
      "pred1 [ 0.00486827  0.00931752  0.00710589 -0.0068939 ]\n",
      "pred0 [ 0.00738806  0.00973238  0.00766126 -0.0072249 ]\n",
      "pred1 [ 0.00501394  0.00876926  0.00730978 -0.00846957]\n",
      "pred0 [ -6.07704520e-02  -2.10941583e-03  -7.17470050e-03   4.01213765e-05]\n",
      "pred1 [-0.06313878 -0.00231451 -0.00753549 -0.00110983]\n",
      "pred0 [ 0.00931937  0.00965004  0.00840472 -0.01035815]\n",
      "pred1 [ 0.00628716  0.00844402  0.0078663  -0.01113672]\n",
      "pred0 [-0.04861349 -0.00066945 -0.00420234 -0.00421175]\n",
      "pred1 [-0.04903352 -0.00103794 -0.0041734  -0.0052579 ]\n",
      "pred0 [ 0.03132129  0.01232703  0.01347908 -0.01528745]\n",
      "pred1 [ 0.0226534   0.01083329  0.01192648 -0.01523878]\n",
      "pred0 [-0.00424033  0.00635925  0.00603084 -0.01191855]\n",
      "pred1 [-0.01163566  0.00458425  0.00473624 -0.01196542]\n",
      "pred0 [-0.05140853 -0.00205846 -0.00396645 -0.00710318]\n",
      "pred1 [-0.05517203 -0.0030116  -0.00448233 -0.00754721]\n",
      "pred0 [-0.0614264  -0.00405843 -0.00584857 -0.00678935]\n",
      "pred1 [-0.06723583 -0.00495333 -0.00683792 -0.0069074 ]\n",
      "pred0 [-0.04810584 -0.00175386 -0.00266539 -0.00920693]\n",
      "pred1 [-0.05042124 -0.00191566 -0.00292398 -0.00965292]\n",
      "pred0 [-0.02936876  0.00159895  0.00166167 -0.01216525]\n",
      "pred1 [-0.02740437  0.00188936  0.00199967 -0.01286765]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4b586f9936eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0;31m#set target as rt + discount_factor*max(Q(st + 1, a_))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                         \u001b[0mmax_actionVal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mget_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetObs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_target_model\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;31m#                         print('max_actionVal', max_actionVal)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                         \u001b[0mq_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetReward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mDISCOUNT_CONSTANT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax_actionVal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-4b586f9936eb>\u001b[0m in \u001b[0;36mget_actions\u001b[0;34m(st, model)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;31m#     print('prediction', result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1025\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[0;32m-> 1027\u001b[0;31m                                   steps=steps)\n\u001b[0m\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1798\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1800\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1299\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#class that is representing single transition in replay memory\n",
    "class Transition():\n",
    "    \n",
    "    def __init__(self, observation0, action, reward, observation1, isTerminal):\n",
    "        self.isTerminal = isTerminal\n",
    "        self.obs0 = observation0\n",
    "        self.action = action\n",
    "        self.reward = reward\n",
    "        self.obs1 = observation1\n",
    "    \n",
    "    def getObs(self, index):\n",
    "        if index == 0:\n",
    "            return self.obs0\n",
    "        elif index == 1:\n",
    "            return self.obs1\n",
    "        else:\n",
    "            raise Excetion('Error', 'Invalid index of observation given in transition getter')\n",
    "\n",
    "    def isTerminal():\n",
    "        return self.isTerminal\n",
    "    \n",
    "    def getReward(self):\n",
    "        return self.reward\n",
    "    \n",
    "    def getAction(self):\n",
    "        return self.action\n",
    "    \n",
    "        \n",
    "\n",
    "def get_actions(st, model):\n",
    "    if len(st) != 4:\n",
    "        raise Exception('Error', 'stateProcessingError!')\n",
    "\n",
    "    st = np.dstack((st[0], st[1], st[2], st[3]))\n",
    "    result = model.predict(np.array([st]))[0]\n",
    "#     print('prediction', result)\n",
    "    return result\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "memory = replay_Memory()\n",
    "\n",
    "#initialize dqn\n",
    "q = DQN()\n",
    "\n",
    "states = []\n",
    "\n",
    "env.reset()\n",
    "\n",
    "for i in range (0, 4):\n",
    "    observation, _, _, _ = env.step(0)\n",
    "    states.append(preprocess(observation))\n",
    "    observation0 = preprocess(observation)\n",
    "#     print(\"After processing: \" + str(np.array(observation0).shape))\n",
    "    plt.imshow(np.array(np.squeeze(observation0)))\n",
    "    plt.show()\n",
    "# print(get_actions(states, q.getModel()))\n",
    "# print(np.argmax(get_actions(states, q.getModel())[0]))\n",
    "\n",
    "\n",
    "\n",
    "#initialize target dqn\n",
    "q_target_model = keras.models.clone_model(q.getModel())\n",
    "q_target_model.set_weights(q.getModel().get_weights())\n",
    "\n",
    "\n",
    "#what percentage of actions are random (improves exploartion rate of the algorithm)\n",
    "\n",
    "\n",
    "#constants\n",
    "\n",
    "EPSILON_EXPLORATION_START = 0.010\n",
    "epsilon = EPSILON_EXPLORATION_START\n",
    "EPSILON_EXPLORATION_END = 0.05\n",
    "EXP_DECAY_FRAMES = 10\n",
    "epsilon_change = (EPSILON_EXPLORATION_START - EPSILON_EXPLORATION_END) / EXP_DECAY_FRAMES\n",
    "TARGET_UDPATE_STEP = 4\n",
    "DISCOUNT_CONSTANT = 0.99\n",
    "REPEAT_ACTION_N = 4\n",
    "\n",
    "rewards = []\n",
    "\n",
    "iter = 0\n",
    "while True:\n",
    "\n",
    "    TARGET_UPDATE_TICK = 0\n",
    "    totalReward = 0\n",
    "    tick = 0\n",
    "    lastAction = env.action_space.sample()\n",
    "    lives = 5\n",
    "    \n",
    "    env.reset()\n",
    "    done = False\n",
    "    \n",
    "    recentStates = deque([], maxlen=4)\n",
    "    \n",
    "    #print('new episode', episode)\n",
    "    \n",
    "    iter += 1\n",
    "    if iter % 25 == 0: \n",
    "        q.saveModel()\n",
    "        \n",
    "    while not done and lives != 1:\n",
    "\n",
    "        #repeat 3 same actions on same frame\n",
    "        if tick < REPEAT_ACTION_N:\n",
    "            observation, reward, done, info = env.step(lastAction)\n",
    "            lives = info['ale.lives']\n",
    "            totalReward += reward\n",
    "            recentStates.append(preprocess(observation))\n",
    "            tick += 1\n",
    "#             print(\"repeat action\", lastAction)\n",
    "        else:\n",
    "            randval = random.uniform(0, 1)\n",
    "\n",
    "            #perform random action\n",
    "            if randval <= 0.01:\n",
    "                lastAction = env.action_space.sample()\n",
    "                observation, reward, done, info = env.step(lastAction) \n",
    "                totalReward += reward\n",
    "                lives = info['ale.lives']\n",
    "\n",
    "                recentStates.append(preprocess(observation))\n",
    "#                 print('doing random action', lastAction)\n",
    "\n",
    "            #perform DQN action\n",
    "            else:\n",
    "                \n",
    "                #get optimal action\n",
    "                \n",
    "                optimal_action = np.argmax(get_actions(recentStates, q.getModel()))\n",
    "#                 print('recentstates LEN, ', len(recentStates))\n",
    "#                 print('optimal action', optimal_action)\n",
    "                #execute optimal action\n",
    "                observation, reward, done, info = env.step(optimal_action)\n",
    "                lives = info['ale.lives']\n",
    "                totalReward += reward\n",
    "                \n",
    "                \n",
    "                #update last action\n",
    "                lastAction = optimal_action\n",
    "                \n",
    "                obs_t0 = recentStates.copy()\n",
    "                \n",
    "                recentStates.append(preprocess(observation))\n",
    "                \n",
    "                obs_t1 = recentStates.copy()\n",
    "\n",
    "                \n",
    "                #save transition in replay memory\n",
    "                transition = Transition(obs_t0, optimal_action, reward, obs_t1, isTerminal=done or lives != 5)\n",
    "                \n",
    "                memory.addUnit(transition)\n",
    "                \n",
    "                #batch = [{ob1, an, r, ob2}...]\n",
    "                batch = memory.getBatch(1)\n",
    "                \n",
    "                if len(memory.getMemory()) < 100:\n",
    "                   continue\n",
    "                #get X for training\n",
    "                X = []\n",
    "                for sample in batch:\n",
    "#                     print('X')\n",
    "                    st = sample.getObs(0)\n",
    "                    train_val = np.dstack((st[0], st[1], st[2], st[3]))\n",
    "#                     print('train_val', train_val.shape)\n",
    "                    X.append(train_val)\n",
    "                X = np.array(X)\n",
    "                \n",
    "                #get Y for training\n",
    "                Y = []\n",
    "                #get the correct Y values\n",
    "                for sample in batch:\n",
    "                    \n",
    "                    sample_action = sample.getAction()\n",
    "                    prediction = get_actions(sample.getObs(0), q.getModel())\n",
    "#                     print('y0', prediction)\n",
    "                    \n",
    "                    # set target as r\n",
    "                    if sample.isTerminal:\n",
    "#                         print('sample action', sample_action)\n",
    "#                         print('reward', sample.getReward())\n",
    "                        prediction[sample_action] = sample.getReward()\n",
    "                        \n",
    "                    #set target as rt + discount_factor*max(Q(st + 1, a_))    \n",
    "                    else:\n",
    "                        max_actionVal = np.max( get_actions(sample.getObs(1), q_target_model) )\n",
    "#                         print('max_actionVal', max_actionVal)\n",
    "                        q_value = sample.getReward() + DISCOUNT_CONSTANT * max_actionVal\n",
    "#                         print(q_value)\n",
    "                        prediction[sample_action] = q_value\n",
    "                        \n",
    "#                     print('prediction Updated', prediction)\n",
    "                    Y.append(prediction)\n",
    "\n",
    "#                 print('Y', Y)\n",
    "                Y = np.array(Y)\n",
    "                    \n",
    "                #perform gradient step update\n",
    "                prediction0 = get_actions(batch[0].getObs(0), q.getModel())\n",
    "                q.getModel().fit(x = X, y = Y, verbose=0)\n",
    "                prediction1 = get_actions(batch[0].getObs(0), q.getModel())\n",
    "                print('pred0', prediction0)\n",
    "                print('pred1', prediction1)\n",
    "\n",
    "                #every TARGET_UDPATE_STEP step copy weights to target network\n",
    "                if TARGET_UPDATE_TICK >= TARGET_UDPATE_STEP:\n",
    "                    TARGET_UPDATE_TICK = 0\n",
    "                    q_target_model.set_weights(q.getModel().get_weights())\n",
    "                TARGET_UPDATE_TICK += 1\n",
    "            tick = 0\n",
    "        env.render()\n",
    "    rewards.append(totalReward)\n",
    "env.close()\n",
    "    \n",
    "    \n",
    "#plot all rewards\n",
    "plt.plot(rewards)\n",
    "plt.ylabel('reward')\n",
    "plt.xlabel('episode')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min(0,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
